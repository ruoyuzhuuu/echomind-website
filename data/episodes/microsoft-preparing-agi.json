{
  "id": "microsoft-preparing-agi",
  "titleCn": "Satya Nadella — 微软如何为AGI做准备",
  "titleEn": "Satya Nadella — How Microsoft is preparing for AGI",
  "originalUrl": "https://www.dwarkesh.com/p/satya-nadella-2",
  "date": "2025-11-12",
  "duration": 3896,
  "tags": [],
  "cover": "/images/microsoft-preparing-agi.jpg",
  "audioUrl": "https://pub-a31ba1df1a8546fe86dc40cba53d796e.r2.dev/microsoft-preparing-agi.mp3",
  "chapters": [
    {
      "title": "微软的未来基础设施战略",
      "start": 66
    },
    {
      "title": "数据中心的10倍提升",
      "start": 134
    },
    {
      "title": "公司工具业务的转型",
      "start": 1349
    },
    {
      "title": "AI代理的自主运作",
      "start": 1800
    },
    {
      "title": "微软的基础设施新视角",
      "start": 2200
    },
    {
      "title": "Azure的开放性与合作策略",
      "start": 3064
    },
    {
      "title": "Code Rabbit的智能审查功能",
      "start": 3600
    }
  ],
  "captions": [
    {
      "start": 0.0,
      "end": 62.532,
      "zh": "欢迎来到EchoMind回声思维。\n\n您现在收听的这期播客，是对原英文博客基于 AI 技术生成的中文版本。我们不仅搬运优质内容，还保留原汁原味的嘉宾音色。\n\n我是Lorraine，在互联网大厂从事数据科学，同时也是一名 AI 爱好者。\n\n探索微软如何为通用人工智能（AGI）时代做好准备，Satya Nadella将带你深入了解科技巨头的战略布局。从大规模投资到与OpenAI的合作，他分享了微软在AI领域的关键举措和愿景。Nadella还讨论了在技术创新中保持道德标准的重要性，确保AI发展不偏离人类价值观。通过具体研究案例，他展示了如何将AI融入日常产品，提升用户体验并推动生产力革命。这个对话充满了深刻洞见，揭示了未来科技发展的前沿动态。\n\n\n\n好，让我们开始吧。",
      "en": "",
      "speaker": -1
    },
    {
      "start": 62.532,
      "end": 109.764,
      "zh": "也许这是工业革命后最大的事情，但同时我觉得现在还是早期阶段。如果你是个model公司，可能会有赢家的诅咒。你可能做了所有艰苦的工作，取得了惊人的创新，但这很容易被复制，变成商品化。我们不想只为某家公司做托管，然后业务都依赖一个客户。那不算生意。你不能为一个model优化整个基础设施。如果这样做，一旦有个突破，你的网络架构就全乱了，那就很可怕了。我们现在做终端用户工具的生意，未来会转变成支持agent工作的基础设施生意。你得考虑的不是未来五年怎么做，而是未来五十年怎么做。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 109.864,
      "end": 118.52506299999999,
      "zh": "今天我们采访Satya Nadella。我和Dylan Patel一起，他是Semianalysis的创始人。Satya，欢迎你。谢谢。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 118.625063,
      "end": 120.714876,
      "zh": "\"太好了，谢谢你来亚特兰大。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 120.814876,
      "end": 133.05181399999998,
      "zh": "\"谢谢你带我们参观新设施，真是太酷了。Satya和Scott Guthrie，微软的云和AI执行副总裁，带我们参观了他们全新的Fairwater 2数据中心，目前是全球最强大的。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 133.151814,
      "end": 150.71981399999999,
      "zh": "\"我们努力每18到24个月把training能力提高10倍。所以这次实际上是个10倍的提升，比GPT5的training规模大10倍。打个比方，这栋楼里的网络光纤数量几乎跟两年半前我们所有Azure数据中心的总和差不多。\"",
      "en": "",
      "speaker": 2
    },
    {
      "start": 150.819814,
      "end": 153.93131400000001,
      "zh": "\"差不多有500万个网络连接。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 154.031314,
      "end": 166.442408,
      "zh": "\"你们在区域间和两大区域之间都铺设了这么多带宽，是不是在为未来的大规模扩展做准备？你们是不是觉得以后会有需要两大区域来训练的超级大模型？\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 166.54240800000002,
      "end": 175.412439,
      "zh": "\"目标是把这些flops聚合起来，用于大型training任务，然后把这些东西整合到一起，对吧？\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 175.51243900000003,
      "end": 176.313533,
      "zh": "\"对。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 176.41353300000003,
      "end": 185.92212700000002,
      "zh": "\"实际上，你会用它来做training，然后用来生成数据，各种推理都会用到。它不是只用在一个工作负载上。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 186.022127,
      "end": 199.50131500000003,
      "zh": "\"你会看到旁边在建的Fairwater 4，也会接入那个一拍比特的网络，这样我们就能以很高的速率连接这两个。然后我们会用AI广域网连接到Milwaukee，那边还有多个Fairwater在建。\"",
      "en": "",
      "speaker": 2
    },
    {
      "start": 199.601315,
      "end": 214.659471,
      "zh": "你可以看到模型并行和数据并行。这基本上是为training任务、pods和超级pods设计的。然后通过广域网，你可以去威斯康星的数据中心，把这些都聚合起来跑一个training任务。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 214.75947100000002,
      "end": 218.718502,
      "zh": "\"我们现在看到的这个机房还没有装服务器，也没有机架。\"",
      "en": "",
      "speaker": 2
    },
    {
      "start": 218.81850200000002,
      "end": 220.65290800000002,
      "zh": "\"一个机房有多少个机架？\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 220.752908,
      "end": 230.516908,
      "zh": "想想看。我们不一定会直接告诉你，但这就是我问的原因。你上去看看，可以开始数数。我们会让你自己数。",
      "en": "",
      "speaker": 2
    },
    {
      "start": 230.61690800000002,
      "end": 232.277158,
      "zh": "\"这个楼里有机房。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 232.377158,
      "end": 234.80365800000004,
      "zh": "\"这部分我也不能告诉你。\"",
      "en": "",
      "speaker": 2
    },
    {
      "start": 234.903658,
      "end": 236.691596,
      "zh": "\"转移注意力很容易，对吧？\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 236.79159600000003,
      "end": 240.03078400000004,
      "zh": "“天啊，这声音挺大的。”",
      "en": "",
      "speaker": 0
    },
    {
      "start": 240.130784,
      "end": 243.323534,
      "zh": "\"你看到了吗？现在我知道我的钱花在哪了。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 243.42353400000002,
      "end": 247.55669,
      "zh": "“就像我在经营一家软件公司。欢迎来到软件公司。”",
      "en": "",
      "speaker": 0
    },
    {
      "start": 247.65669000000003,
      "end": 253.798378,
      "zh": "\"设计空间有多大？用了GB200s和NVLink后，还有多少其他决定要做？\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 253.89837800000004,
      "end": 276.182378,
      "zh": "“这涉及从model架构到物理计划的优化。不过这也有点吓人，因为新芯片会出来，比如Vera Rubin Ultra，它的功率密度和散热需求会很不一样，对吧？所以你不想只按一个规格来做。这就回到我们之前聊的，你想要随时扩展，而不是一次做好就不动了。”",
      "en": "",
      "speaker": 0
    },
    {
      "start": 276.28237800000005,
      "end": 312.8583780000001,
      "zh": "\"回顾以往的技术变革，不管是铁路、互联网、可替换零件、工业化还是云计算，每一次革命从技术发现到普及都越来越快。很多在doorkesh播客上的人认为这可能是最后一次技术革命。而这次真的很不一样。至少在市场上，短短三年，我们就已经看到Hyperscalers明年要投入5000亿美元的资本支出，这个速度和规模是之前无法比的。而最终结果似乎也不太一样。你的看法好像跟那些认为AGI快来了的AI狂热者不太一样，我想多了解一下你的观点。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 312.95837800000004,
      "end": 376.03037800000004,
      "zh": "我觉得，这次可能是工业革命之后最大的事了，所以我从这个角度出发。但同时，我也觉得现在还在初期阶段。我们确实做出了一些很有用的东西，也看到了不错的效果。这些扩展规律似乎在起作用，我挺乐观的，觉得它们会继续有效。这需要一些真正的科学突破，但也涉及很多工程问题。不过话说回来，即便是过去70年的计算发展，也一直在推动我们前进。就像Raj Reddy说的，他是CMU的图灵奖得主，他一直有一个比喻，说AI应该是守护天使或认知放大器。我很喜欢这个说法，简单明了说明了AI对人的用处：认知放大器和守护天使。所以我把AI看作工具，但也可以说这不只是个工具，它做了很多以前只有人能做的事。不过，很多过去的技术也是这样，很多事情以前只有人能做，后来就有工具来做了。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 376.13037800000006,
      "end": 387.17147200000005,
      "zh": "\"我想我们不必纠结定义，不过可以这样想，也许需要5年、10年、20年，总有一天机器会生成satya tokens，对吧？然后微软董事会觉得这些satya tokens很值钱。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 387.2714720000001,
      "end": 390.16237800000005,
      "zh": "\"你觉得采访Satya会浪费多少经济价值呢？\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 390.26237800000007,
      "end": 415.67837800000007,
      "zh": "我可付不起satya tokens的API费用，所以不管你怎么叫它，satya tokens是工具还是agent都行，对吧？现在，如果你的models每百万tokens成本在几美元或几美分，那就有很大的扩展空间，利润空间也很大。问题是，这个利润会流向哪里，微软在其中的参与程度又有多深？这是我关心的。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 415.7783780000001,
      "end": 489.9383780000001,
      "zh": "所以我觉得，从某种意义上来说，这又回到了经济增长到底会是什么样子？公司会是什么样？生产力会是什么样？这让我想到，工业革命之后，可能经过70年的扩散期，你才开始看到经济增长，对吧？即使这次技术扩散很快，但要实现真正的经济增长，工作成果和工作流程也得改变。这是我认为企业变革管理的重要性，不容忽视。所以往后看，人和他们创造的tokens会不会有更高的杠杆？不管是未来的Dwarkesh tokens还是Dylan tokens。想想看，没有技术你能做半导体分析或者这个播客吗？根本不可能，对吧？你能达到的规模是有多大？不可能。所以问题是，这个规模会不会通过某些东西提升10倍？绝对会。因此，不论是收入增长还是观众数量增长，我觉得这就是会发生的事。就是说，工业革命花了70年、也许150年才能达到的变化，现在可能在20年、25年就能实现。如果幸运的话，我真希望能把工业革命200年的变化压缩到20年里。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 490.0383780000001,
      "end": 529.7463780000002,
      "zh": "微软一直以来可能是最厉害的软件公司，也是最大的SaaS公司。你知道的，以前是卖Windows授权和光盘，现在是卖365订阅。这是个转变，对吧？软件服务的用户边际成本很低，不过研发和获客成本很高。这也是为什么SaaS公司在市场表现不佳，因为AI的成本太高了，彻底打破了这些商业模式。作为可能是最厉害的软件公司，你怎么让微软适应这个新时代，在这个时代里，成本变得很重要，而每个用户的边际成本也不同？毕竟现在你们收费是，比如说，Copilot要20美元。",
      "en": "",
      "speaker": 3
    },
    {
      "start": 529.8463780000001,
      "end": 654.0103780000002,
      "zh": "是啊，我觉得这是个好问题，因为某种意义上商业模式本身的杠杆还在。如果你看从消费者到其他领域的models，会有广告单元、交易、AI设备的毛利、订阅——无论是消费者还是企业的，还有消费模式。我还是觉得这些就是所有的计量方式。说到订阅，大家喜欢订阅是因为可以规划预算，对吧？它们基本上是一些消费权利的打包。所以这其实是个定价决定。你有权消费多少，如果你看所有的编码订阅，这就是它们的本质，然后你有专业版、标准版等等。我觉得这就是定价和利润结构的分层方式。有趣的是，微软的好消息是，我们在这些计量方式上都有涉及。实际上，从整体来看，我们几乎有消费订阅，涵盖了所有其他消费者的杠杆。时间会证明哪种模式在哪种类别中有意义。你提到SaaS，我经常想的是，比如Office 365或Microsoft 365。低ARPU挺好的，因为在从服务器到云的过渡中，我们曾经问自己，如果我们只是把使用我们Office授权和服务器的用户搬到云上，成本会缩小我们的利润，我们会变得不那么赚钱。但实际发生的是，搬到云上后市场扩展得很疯狂。我们在印度只卖了几台服务器，但在云上，突然每个人都可以部分购买服务器，IT成本大幅下降。我没想到的是，大家在SharePoint下买存储花了很多钱，EMC可能最大的部分就是SharePoint的存储服务器。所有这些在云上就不需要了，实际上是现金流出。所以市场大幅扩展。AI也会这样，比如你看GitHub和VS Code，我们花了几十年建的东西，突然间编码助手一年就做到了这么大。我觉得市场也会这样大幅扩展。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 654.1103780000001,
      "end": 682.2263780000001,
      "zh": "我觉得问题是市场会不会扩展，微软相关的收入会不会也跟着增长？比如Copilot，今年年初的时候，根据Dylan的数据，GitHub Copilot的收入大概是五亿，没有什么竞争对手。现在有了Claude、Code Cursor和Copilot，收入都差不多在十亿左右，而Codex也在追赶，差不多七八亿。所以问题是，在微软能接触到的所有服务中，微软版Copilot的优势是什么？",
      "en": "",
      "speaker": 1
    },
    {
      "start": 682.3263780000001,
      "end": 873.954378,
      "zh": "对了，我特别喜欢这个图表。你知道，我喜欢它的原因有很多。一个是我们还在榜首。第二是这里列出的公司都是过去四五年才成立的。这对我来说是个好兆头，对吧？有新对手、新挑战。你说，哎，现在是谁？Claude会干掉你，Cursor会干掉你。不是Borland，对吧？所以谢天谢地，这说明我们走对方向了。我们从无到有，这就是市场扩展。这就像云计算一样，编码和AI这类可能会成为最大类别，甚至可能超过知识工作。所以我希望自己保持开放心态，我们会有激烈竞争。我觉得你说得对，这点很好。但老兄，我很高兴我们利用现有的资源，现在我们得竞争了。即便在刚过去的季度，我们的季度公告显示，用户从两千万增长到两千六百万。我对用户增长和发展方向感觉不错。但更有趣的是，猜猜这些生成大量代码的家伙们的repos都去哪了？都去GitHub了。GitHub在repo创建、PR等方面都创了新高。所以我们想保持开放。这意味着我们要搞清楚，因为我们不想把它和自己的增长搞混。有趣的是，现在每秒钟有一个开发者加入GitHub，这是个数据。然后80%的人会自然而然用上GitHub copilot的工作流。顺便说一下，很多东西甚至会用到我们默认开启的代码审查agents，因为你可以用。所以我们有很多结构性的机会。我们还要做的是从GitHub的基础功能开始，像Git到issues到actions。这些都很强大，因为它们围绕你的repo构建。所以上周在GitHub Universe，我们就是这么做的。我们说要打造Agent HQ这个概念。比如你有个叫任务控制的东西，你去任务控制。我有时把它描述为AI agents的有线电视，因为我会把Codex、Claude、Cognition等打包成一个订阅。这样我可以发起任务，指挥它们。它们会在各自的分支上工作，我可以监控它们。我觉得这会是个创新的巨大机会。因为现在我想用多个agents，想消化多个agents的输出，想掌控我的repo。所以如果需要建立某种抬头显示器，快速指挥和筛选代码agents生成的东西。对我来说，在VS code、GitHub和这些新的基础功能之间，我们会把它们作为任务控制来构建。我觉得有个控制面板的可观察性，想想看，所有部署这些的人都会需要观察哪个agent在什么时候对哪个代码库做了什么。所以我觉得这是个机会，最终你的观点很有道理，我们必须保持竞争力和创新，不然就会被击败。但只要我们还在榜首，我就喜欢这个图表，即便有竞争。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 874.054378,
      "end": 912.502378,
      "zh": "关键在于GitHub会继续增长，不管哪个coding agent赢。但这个市场每年增长10%、15%、20%，远超GDP，是个不错的复合增长。不过这些AI coding agents从去年年底的5亿美元增长到了现在的50、60亿美元。这是个10倍的增长，对吧？那么软件agents的总市场规模到底有多大？是2万亿美元的工资，还是更高？因为现在每家公司都能多开发软件了。微软肯定会分一杯羹。但在一年内，你的市场份额从接近100%或至少50%以上跌到了25%以下。大家对微软的信心在哪呢？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 912.602378,
      "end": 977.546378,
      "zh": "其实，Dylan，说到底，我们没有什么与生俱来的优势，唯一可以依靠的就是不断创新。幸运的是，这个市场比我们之前占大份额的任何市场都要大。可以这么说吧，我们在VS Code和GitHub上的市场份额挺高，那是个不错的市场。但是，哪怕在一个更大的市场里占据一小部分，也很不错。你看，以前我们在客户端服务器和服务器计算上份额挺高，但在超大规模计算上份额低多了，但这生意大得多。所以至少微软证明了，即便市场份额不如以前，只要我们参与的市场在创造更多价值，并且有多个赢家，我们就能过得去。我明白你的意思，最终还是得有竞争力。我每个季度都会关注这些数据，所以我对我们在GitHub HQ或Agent HQ上的计划很乐观。把GitHub打造成所有agents聚集的地方，我们会有多次机会，不一定只有一个赢家和一个订阅。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 977.646378,
      "end": 1020.270378,
      "zh": "其实，关注这个问题的原因不仅仅是关于GitHub，而是涉及到Office和微软提供的其他软件。一个可能的AI发展方向是，models会一直受限，所以你需要实时观察。而另一个方向是，随着时间推移，这些models现在能做几分钟的任务，未来可能会做十分钟、三十分钟，甚至几天的工作。然后model公司可能会收取高额费用，就像为你提供一个可以用任何界面和人沟通的同事，可以在不同平台之间切换。如果我们接近这个未来，为什么model公司越来越赚钱，占据所有利润，而搭建这些结构的地方，随着AI能力提升，变得不那么重要呢？这关系到现在的Office和那些能独立完成知识工作的“同事”之间的区别。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1020.3703780000001,
      "end": 1105.222378,
      "zh": "这是个好问题。我觉得这就看价值到底是全跑到model那边，还是在model和支撑结构之间分配。时间会告诉我们答案。不过，我的基本观点是，激励结构会变得清晰。比如说，信息工作或者编码工作。其实，我在GitHub Copilot里最喜欢的一个设置叫auto，就是自动优化。实际上，我订阅了这个，auto会根据我的需求来优化，甚至能全自动处理，还能在多个models之间调配tokens来完成任务。所以，如果这么看，models会变成商品。特别是有了开源model，你可以选个checkpoint，加上一堆自己的数据，就能用了。我觉得无论是Cursor还是微软，大家都会开始用一些自有models，然后把大部分任务交给它们。所以说，如果你在支撑结构上赢了，解决了这些智能问题的各种麻烦，那你就能和model整合，因为你有数据的流动性。还有很多可用的checkpoints。所以从结构上看，总会有一个开源model可以用，只要你有数据和支撑结构。所以可以说，如果你是model公司，可能会有赢家的诅咒，做了很多创新工作，但却可能被商品化，因为别人可以用数据来训练这些checkpoints。所以这个问题可以从两方面看。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1105.322378,
      "end": 1158.026378,
      "zh": "拆开来说，你刚才提到的，世界上有两种看法，对吧？一种是认为有很多不同的models，开源也存在，这些models之间的差异会决定谁赢谁输，但真正让你赢的是支撑结构。另一种看法是models才是关键的知识产权。确实，大家都在激烈竞争，比如我可以用Anthropic或者OpenAI，你可以从收入图表中看到这一点，对吧？像OpenAI的收入一旦有了类似Anthropic的代码model后就开始飙升，虽然方式不同。有种观点认为，model公司实际上是拿走所有利润的，因为看看这一年，至少在Anthropic，他们的推理毛利率从不到40%涨到超过60%。即便有更多中国开源models，OpenAI和Google的竞争，X Grok也在竞争，但在model层的利润率还是显著增长。你怎么看这个问题？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 1158.1263780000002,
      "end": 1280.2383780000002,
      "zh": "这是个好问题。我觉得几年前大家可能会说，只要包个model就能成功，但这想法被打破了，因为model的能力和工具的使用。比如我们做了个小东西叫Excel Agent，挺有意思的。它不是简单的UI包装，而是个中间层的model。因为我们有GPT家族的IP，把它放到Office系统的核心层，教它原生理解Excel的所有东西。所以不只是看像素，而是完全理解Excel的本质。比如说，给它一些推理任务，它能纠正我的错误，它不只是看像素，而是看公式哪里错了，并理解它。\n\n所以这不是在UI层面用prompt，而是在中间层教它Excel的所有工具。我们甚至用markdown教它做高级Excel用户的技能。这有点像回到AI大脑，你不仅仅是在做Excel，而是在用这个model把Excel的商业逻辑用认知方式包装起来。因此，Excel自带分析师和所有工具，这样的东西会被大家做出来。\n\n即便是model公司也得竞争，如果他们定价高，我做工具的就会替代他们。我可能暂时用一下，但只要有竞争，就会有赢家通吃的情况。如果有一个model比其他的都强，那就是赢家通吃。但只要有多个model的竞争，就像超大规模计算的竞争，还有开源的checks，这里就有足够的空间在model之上创造价值。\n\n在微软，我们会在支持多个models的超大规模业务中。我们还有七年可以用OpenAI的models，在此基础上创新。所以我觉得我们有个前沿级的model，可以灵活创新。我们会用mai建立自己的models，然后在安全、知识工作、编码或科学领域构建应用框架，这些都会是以model为核心的，而不是简单包装model，而是把model整合到应用中。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1280.3383780000001,
      "end": 1312.378378,
      "zh": "我有很多问题想问你刚才提到的其他事情，但在我们深入那些话题之前，我还是想知道，这是不是对AI能力的展望有点不够前瞻呢？因为你想象的model就像现在这样，只能截个屏，但看不到每个单元格里的公式。我觉得更好的理解方式是，把它想象成人类。你想啊，这些models其实将来能像人一样用电脑。一个用Excel的人类知识工作者，可以查看公式，使用其他软件，如果需要还能在Office365和其他软件之间迁移数据等等。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1312.4783780000002,
      "end": 1313.7555030000003,
      "zh": "\"我就是这个意思。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1313.8555030000002,
      "end": 1317.1295340000001,
      "zh": "\"但如果真是这样，那跟Excel的整合就没那么重要了。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1317.2295340000003,
      "end": 1326.9122840000002,
      "zh": "\"别担心Excel的整合。毕竟，Excel本来就是为分析师设计的工具。很好，所以不管哪个AI是分析师，它都应该有这些工具。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1327.0122840000004,
      "end": 1328.4519400000004,
      "zh": "\"能用电脑。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1328.5519400000003,
      "end": 1329.2717840000003,
      "zh": "“对。”",
      "en": "",
      "speaker": 3
    },
    {
      "start": 1329.3717840000004,
      "end": 1332.8199720000005,
      "zh": "\"就像人会用电脑一样，这是他们的工具。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1332.9199720000004,
      "end": 1334.4060660000005,
      "zh": "\"电脑就是工具。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1334.5060660000004,
      "end": 1335.5277540000004,
      "zh": "\"对。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1335.6277540000003,
      "end": 1343.3019730000003,
      "zh": "好吧，我的意思是，我在做一个分析师，基本上就是个AI agent，它本来就知道怎么用这些分析工具。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1343.4019730000002,
      "end": 1349.1605360000003,
      "zh": "但是我们是不是要确认一下，我们说的是同一件事？就像我作为播客主播用Excel一样。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1349.2605360000002,
      "end": 1369.5285360000003,
      "zh": "我不太会用Excel，完全靠自己。所以想象一下我的工作方式。我们现在可能要聊聊我对公司未来的看法。对，公司未来就是工具业务，我有电脑，用Excel，未来还会有个copilot，那个copilot也会有agents。对吧，但还是我在掌控一切。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1369.6285360000002,
      "end": 1370.5225050000001,
      "zh": "\"嗯。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1370.6225050000003,
      "end": 1374.5002550000004,
      "zh": "一切都会回到正轨。这就是一个世界的样子。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1374.6002550000003,
      "end": 1375.3200990000003,
      "zh": "\"嗯。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1375.4200990000004,
      "end": 1380.6678180000004,
      "zh": "\"然后第二种情况是，公司直接给AI agent提供计算资源。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1380.7678180000005,
      "end": 1382.3816310000004,
      "zh": "\"对。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1382.4816310000006,
      "end": 1388.9600060000005,
      "zh": "\"这样的话，它就能完全自主运作了。这个自主的agent会有一整套相同的工具。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1389.0600060000006,
      "end": 1390.5461000000007,
      "zh": "\"对。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1390.6461000000006,
      "end": 1429.2381000000007,
      "zh": "\"这些工具都可以用。对吧。所以这个AI工具不仅仅是一个简单的计算机，因为用工具来完成任务会更省token。其实，我觉得我们的业务，从原来的终端用户工具业务，会变成支持agent工作的基础设施业务。这是另一种看法。对吧。所以你会看到我们做的一些事情，比如我们在M365下面构建的东西，依然很重要。你需要有地方存储、归档、发现和管理所有这些活动，即使你是一个AI agent。这算是一种新的基础设施。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1429.3381000000006,
      "end": 1448.9221000000007,
      "zh": "\"所以我确认一下你的意思，你是说，未来那些能实际使用计算机的AI，即使不和Microsoft合作，也能用Microsoft的软件。但如果你用我们的基础设施，我们会给你更底层的访问权限，让你更高效地完成本来就能做的事情。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1449.0221000000006,
      "end": 1514.7941000000005,
      "zh": "完全正确。其实整个过程是这样的：最开始我们有服务器，然后出现了虚拟化，服务器就更多了。所以不要把工具看成最终的东西，想想人用的整个底层环境。而这个底层环境也是AI agent的启动平台，因为AI agent也需要电脑。这是一个方面。我们看到的一个有趣现象是，很多在做办公文档和各种自主agent的人，想要配置Windows 365。是的，他们真的想给这些agent配置一台电脑。所以，我觉得我们会发展成一个终端用户计算基础设施业务，而且会不断增长，因为它的增长速度会超过用户数量。人们常问我，每用户业务会怎么样？至少目前来看，可能要把每用户业务看成是每用户和每agent的结合。关键是要给每个agent配置什么？一台电脑、一套安全措施、一个身份，还有观察和管理层面。这些都会整合进去。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1514.8941000000007,
      "end": 1574.0421000000006,
      "zh": "我现在的看法是，这些模型公司都在构建环境，训练他们的模型去用Excel、亚马逊购物，或者订机票什么的。同时，他们也在训练这些模型进行迁移，因为这可能是最直接有价值的事情。对吧？比如把大型机系统转成标准的cloud系统，把Excel数据库转成用SQL的真实数据库，或者把Word和Excel里的东西转成更程序化、更高效的形式，这些其实人也能做，但对软件开发者来说不划算。接下来几年，大家可能都会用AI来大幅提升价值。那微软在这方面怎么融入呢？如果这些模型能自己用工具去完成迁移。微软在数据库、存储等领域是有领导地位的，但像office这样的生态系统的使用可能会大幅减少，就像大型机生态系统的使用可能会减少一样。虽然过去二十年大型机其实还在增长，尽管很少有人提起，但它们还是增长了100%。",
      "en": "",
      "speaker": 3
    },
    {
      "start": 1574.1421000000007,
      "end": 1575.0360690000007,
      "zh": "我同意。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1575.1360690000008,
      "end": 1577.690288000001,
      "zh": "\"那接下来会怎么发展呢？\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 1577.7902880000008,
      "end": 1685.9342880000008,
      "zh": "嗯，我的意思是，最终这不是说有很长一段时间会是个混合世界，对吧？因为人们会用工具，而这些工具要和agent一起工作。而且，他们还得互相沟通。我生成的东西，人类也得能看。所以这些都是任何地方都会考虑的实际问题。输入输出都是。所以我觉得不只是说，我迁移了就完事。但关键是，我得在这个混合世界中生存。不过这还没完全回答你的问题，因为可能会有一个新的高效前沿，我强调的是agent和agent的合作，完全优化。即使是agent和agent在一起工作，也需要什么基础？需要一个存储系统吗？那个存储系统需要E discovery吗？E discovery需要可观察性吗？需要一个可以用多个模型的身份系统吗？这些都是我们今天Office系统的底层框架，我觉得未来也是。你提到数据库，对吧？我很希望Excel都有数据库的后台。实际上，我希望这个马上就能实现。而且那个数据库得是个好数据库。实际上，数据库会是一个大增长点。如果我想到所有Office的东西结构化得更好，因为agent的世界会更好地连接结构化和非结构化数据，这会推动基础设施业务的发展。其实，这一切都是由agent驱动的。你可以说，这些都是模型公司即时生成的软件。这也可能是真的。我们也会成为这样的模型公司之一。所以我们会参与进来。竞争可能在于我们会构建一个模型加上所有基础设施，然后在那些能做到的人之间展开竞争。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1686.0342880000007,
      "end": 1718.0022880000008,
      "zh": "\"说到模型公司，你说我们也会成为其中之一。我们不仅有基础设施，也会有自己的模型。现在，微软AI最近发布的模型在两个月前在Chatbot Arena排第36名。你们显然有OpenAI的知识产权。那么问题是，首先你同意这个排名吗？为什么会这样？特别是考虑到你们理论上有权利直接分支OpenAI的代码库或者提取他们的模型。对吧？特别是如果你们的战略是要成为一个领先的模型公司。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 1718.1022880000007,
      "end": 1835.8222880000008,
      "zh": "嗯，我的意思是，首先我们会在所有产品中最大化使用OpenAI的模型。对吧，我觉得这是我们未来七年会一直做的事情。不仅用，还要增加价值。比如分析师、Excel agent这些，我们会做RL fine-tuning，在GPT家族上进行一些中期训练，因为我们有独特的数据资产，可以建立能力。好消息是，根据新协议，我们可以明确组建一个世界级的超智能团队，雄心勃勃地去追求。同时，我们要聪明地利用这些资源。这意味着我们既要专注产品，又要专注研究。因为我们可以访问GPT家族，我不想浪费算力做重复的事。所以我要用好我们的算力，最大化GPT家族的价值。比如我们推出的图像模型，在图像领域排名第九，用于成本优化，在Copilot和Bing中都有使用。我们还有一个带个性的音频模型，优化在我们的产品中，所以即便在LM领域，我们也开始做文本模型，首次亮相时排第十三，只有15000个H100，算是个小模型。这样证明了我们的核心能力，跟随指令等方面都达到了先进水平。这也让我们看到，如果有更多算力，我们能做什么。接下来我们会做一个omni模型，把我们在音频、图像、文本上的工作结合起来，这是MAI的下一个阶段。所以在MAI的路线图上，我们会组建一流的超智能团队，继续在公开场合推出一些模型。这些模型要么在我们的产品中使用，因为它们延迟低、成本低，或者有些特殊能力。我们会做真正的研究，为下一波突破做好准备。与此同时，利用我们有的GPT家族优势。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1835.9222880000007,
      "end": 1883.7302880000007,
      "zh": "假设七年后，我们不能再用OpenAI的模型。微软怎么确保自己还是顶尖的AI实验室呢？OpenAI和Google在扩展和推理方面都有很多突破，但这也是人才的竞争。你看Meta花了超过200亿美元挖人，Anthropic去年从Google挖走了整个Blue Shift推理团队，Meta最近也从Google挖了一大批推理和后期训练团队。这种人才大战很烧钱。如果你在基础设施上花1000亿美元，那也得在用这些基础设施的人身上花钱，才可能更有效率地取得新突破。我们怎么能相信微软会有世界级的团队，能取得这些突破呢？虽然现在你们在花钱上比较谨慎，避免重复工作，但如果需要大笔投入，怎么能确保一下子就能冲到前五的水平呢？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 1883.8302880000006,
      "end": 1961.8422880000005,
      "zh": "我觉得最终我们会组建一个世界级的团队，其实我们已经开始这样做了。Mustafa加入了我们，还有Karen和Amar Subramaniam，他在Gemini 2, 5做了很多后期训练的工作，现在在微软。Nando也在这儿，他在DeepMind做过很多多媒体的工作。所以我们会继续打造一个顶尖的团队。其实，我觉得这周晚些时候，Mustafa还会发布些关于我们实验室计划的更清晰信息。我想让大家知道的是，我们会构建支持多种模型的基础设施。我们想从大规模的角度打造一个能支持所有模型需求的最大规模基础设施，不管是开源的还是来自OpenAI和其他公司。这是我们的一个任务。第二，在我们自己的模型能力上，我们会在产品中使用OpenAI的模型，也会开始打造自己的模型，比如在GitHub Copilot中用到的Anthropic模型。我们甚至会把其他前沿模型整合到我们的产品中。所以，我觉得最终产品能否完成特定任务才是最重要的，我们会根据这个来进行垂直整合，只要产品服务市场好，就可以优化成本。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 1961.9422880000006,
      "end": 2015.5822880000007,
      "zh": "其实有个问题要考虑。现在的模型在training和inference上有区别，但未来可能这种区别会越来越小。如果你期待有像人类智力的东西，人类是在工作中学习的。想想你过去30年，是什么让satya tokens这么有价值？是你在微软30年的智慧和经验。未来如果模型达到人类水平，它们也能在工作中持续学习，这会给领先的模型公司带来巨大价值。因为你可以把一个模型的副本广泛部署到经济中，学会每个工作。而且和人不同，它们能把学到的东西整合进模型里。这种持续学习的方式，像是指数级的反馈循环，几乎像是智能爆炸。如果那时候微软不是领先的模型公司，那替换一个模型可能影响不大，因为一个模型能搞定经济中的每个工作，其他长尾的就不太重要了。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 2015.6822880000007,
      "end": 2062.950288000001,
      "zh": "是啊，我觉得你说的有道理，如果有一个模型是全世界最广泛使用的，并且它能持续学习，那基本上就稳赢了，对吧？但实际上我看到的情况是，即使现在任何一个模型再强势，也不是这样的。就像数据库一样，不可能只有一个数据库被大家用，因为有不同的使用场景。所以我觉得会有一些网络效应，比如持续学习或者数据流动性，但不会在所有领域、所有地区、所有细分市场同时发生。我觉得设计空间很大，还有很多机会。你的核心观点是需要在基础设施层、模型层和支架层都具备能力，然后能把这些东西组合起来，不仅仅是垂直整合，而是根据用途去组合。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2063.050288000001,
      "end": 2063.9442570000006,
      "zh": "对吧？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2064.044257000001,
      "end": 2124.920257000001,
      "zh": "你不能只为了一个模型去优化基础设施。要是落后了怎么办？到时候所有的基础设施投入都浪费了吧？你得建设能支持多种模型的基础设施。否则，如果只为一个模型架构优化，就等于说一旦别人有什么突破，你整个网络拓扑就没用了。挺吓人的，对吧？所以你得让基础设施能支持各种可能出现的模型。要是你真的想做大规模业务，这方面是必须重视的。如果你想成为一家模型公司，就得考虑怎么让别人能在你的模型上做事，才能有一个ISV生态系统。否则你不可能拥有每个类别，也就不会有API业务。这样的话，你就不可能成为一个能成功部署到各地的平台公司。所以行业结构会逼着大家去专注。在这种专注中，像微软这样的公司应该在每一层都凭实力竞争，而不是想着通过垂直整合来赢得一切。这是行不通的。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2125.020257000001,
      "end": 2183.052257000001,
      "zh": "根据Dylan的数据，明年AI资本支出就要达到五千亿美金了。各大实验室已经在花数十亿去抢顶级研究人才。但如果没有足够的高质量数据来训练，这些都没用。没有合适的数据，再先进的基础设施和顶尖的人才也无法为用户带来价值。这就是Libelbox的用武之地。Libelbox能大规模生产高质量数据，支持你想让模型具备的任何能力。不管你需要的是一个能对多小时轨迹提供详细反馈的coding agent，还是一个需要数千个日常任务样本的机器人模型，或者是一个能为用户执行现实操作的语音agent，比如帮他们订个快闪活动。要说明的是，这可不是现成的数据。Labelbox能在48小时内设计并启动一个定制化的大规模数据pipeline，并在几周内为你提供数万个有针对性的例子。想了解更多，去Labelbox.com看看吧。好，回到Satya的话题。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 2183.152257000001,
      "end": 2220.916257000001,
      "zh": "“去年微软本来有望成为最大的基础设施提供商。你们在23年就最早开始布局，租用数据中心、启动建设、确保电力，各种资源都搞定了。你们本来有望在26或27年超过亚马逊，28年肯定能超过。但从去年下半年开始，微软突然暂停了一些租赁项目，结果这些地方被谷歌、Meta、亚马逊，有时是Oracle接手了。我们现在就在世界上最大的一个数据中心里坐着。所以，显然不是所有项目都停了，你们还在疯狂扩张，但确实有些地方停工了。为什么这样做？”",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2221.016257000001,
      "end": 2371.208257000001,
      "zh": "对，我的意思是，这其实回到超大规模业务的本质。我们决定要把Azure打造成支持AI各个阶段的平台，从训练到中期再到数据生成和推理。我们需要让整个系统灵活可变。所以我们并没有针对某一代产品大规模扩容。因为我们发现，每18个月要增加10倍的训练能力，才能满足OpenAI各种模型的需求。关键是要保持这种节奏，但更重要的是要平衡，不仅仅是训练，还要能在全球范围内服务这些模型。最终，盈利的速度决定了我们能否继续投资。而基础设施必须支持多种模型。所以我们做了调整，现在我们在更多地方开始布局。无论是建设、租赁还是GPUs服务，我们都在根据需求和训练需求进行扩展。我们不想只为一家客户服务，那不算是个好生意。OpenAI要成为独立公司，这很好。Meta也用第三方的容量，但他们都有自己的超大规模能力。我们的目标是建立自己的超大规模系统和研究计算资源。这就是我们的调整。我很有信心。还有一点是，我不想被某一代产品的大规模绑住。GB2和GB3都来了，到Vera Rubin Ultra的时候，数据中心会很不一样，因为每个机架、每行的功率和冷却需求都会不同。我不想只为某一代产品建很多千兆瓦的容量。所以说，节奏、灵活性、位置、工作负载多样性、客户多样性都很重要，我们正朝这个方向努力。我们还学到，每个AI工作负载不仅需要AI加速器，还需要很多其他东西。实际上，我们的利润结构很大一部分在这些其他东西上。所以，我们想把Azure打造成能支持各种工作负载的平台。因为这才是超大规模业务，同时我们也要在最顶级的训练上保持竞争力，但不能让它压倒其他业务。我们不是只做五个客户的裸金属服务，这不是微软的生意。我们做的是超大规模业务，支持AI工作负载的长尾需求。为此，我们会提供一些领先的裸金属服务能力，给一些模型，包括我们自己的。这就是我们追求的平衡。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2371.308257000001,
      "end": 2399.028257000001,
      "zh": "你看，关于这个可替代性的问题，还有另一个疑问。你可能希望它在像亚特兰大这样的人口中心。我们就在这里。不过，随着AI任务的范围不断扩大，这个位置到底有多重要呢？好问题，其实你知道吗，像推理prompt可能需要30秒，深度研究需要30分钟，软件agent可能要几个小时，甚至几天。人机交互的时间为什么重要呢？如果…",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2399.128257000001,
      "end": 2400.486632000001,
      "zh": "这是个好问题。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2400.5866320000014,
      "end": 2403.9535380000016,
      "zh": "“地点A、B或者C。没错，就是这样。”",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2404.0535380000015,
      "end": 2466.1895380000014,
      "zh": "所以，这也是我们为什么要考虑Azure区域的样子，以及这些区域之间的网络关系。随着模型能力的发展，还有这些tokens的使用，不管是同步还是异步，你不想在位置上出问题。另外，数据驻留法律也很重要，比如整个欧盟的情况，我们得创建一个欧盟数据边界，这意味着即使是异步的请求也不能随便发到别的地方。所以我们可能需要一些高密度的区域，还得考虑电力成本。不过你说得对，拓扑结构在我们扩展时必须演变，要考虑每个token的经济性，包括使用模式，像是同步异步的使用模式，还有计算存储，因为某些事情的延迟可能很关键，存储必须就位。如果我有个Cosmos DB靠近这个地方用于会话数据，或者是个自主系统，那也必须靠近。所以，我觉得这些因素都会影响超大规模业务的发展。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2466.2895380000014,
      "end": 2502.2535380000013,
      "zh": "你知道，暂停之前，你们的预测是，到2028年会达到12、13吉瓦，现在大概是九吉瓦半。对吧。但有件更相关的事，我想更明确地说，这不是你们想做的生意。但像Oracle，从你们的五分之一规模，到2027年底会比你们更大。虽然他们的投资回报率达不到微软的水平，但毛利率也有35%。问题是，这是不是微软应该做的生意呢？你们现在拒绝这个业务，等于放弃了优先权，结果造就了一个新的超大规模企业。",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2502.353538000001,
      "end": 2554.373538000001,
      "zh": "我没这个打算。首先，我不想抹杀Oracle在建立业务上的成功，我祝他们好运。其实我想说的是，我们没必要超越成为一个模型公司的宿主，这个决定对我们来说不合适。关键要考虑的不是未来五年做什么，而是未来五十年做什么。这就是我们做决定的依据。我对我们和OpenAI的合作很有信心，我们的业务也不错。我们也祝Oracle成功，事实上，我们也是他们容量的买家。我们希望他们越来越好。但我觉得我们要做的事情已经很清楚了，不是去追逐别人。虽然我很关注你提到的AWS、Google和我们的情况，我觉得这些信息很有用，但不代表我要去追赶他们。我得考虑的不仅是短期内的毛利率，而是微软能独特做到的事情，这才是我们要做的。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2554.473538000001,
      "end": 2587.701538000001,
      "zh": "我有个问题，撇开这些不谈，我明白你的意思，做有更多客户的生意确实更划算，而不是只给几个实验室提供基础设施。但问题是，行业的发展方向是什么？如果我们相信AI会越来越智能，那为什么行业的形态不是OpenAI、Anthropic和DeepMind成为平台，而这些企业需要基础设施时就和他们合作？他们是平台，那谁是直接用Azure的长尾客户呢？因为你知道，大家都想用通用智能。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 2587.801538000001,
      "end": 2654.509538000001,
      "zh": "“在Azure上可用，对吧？任何工作负载，如果你想用一些开源模型和OpenAI的模型，比如你去Azure Foundry，现在你可以配置这些模型，购买PTUs，获取Cosmos DB、SQL DB、存储和计算。这才是实际的工作负载，不只是调用一个API，而是需要这些东西来构建应用。事实上，模型公司也需要这些来创建东西，不只是有个token工厂，而是要有这些资源。这就是超大规模业务，不是一个模型，而是所有这些模型。所以如果你想要GROQ加上OpenAI加上开源模型，就来Azure Foundry配置它们，构建你的应用。这里有个数据库，这就是业务的样子。还有个不同的业务，就是卖裸金属服务给模型公司。关键在于你想参与多少这样的业务。这是个很不同的业务领域，我们参与其中，但也有限度，不能让它挤压其他业务空间。这就是我的看法。”",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2654.609538000001,
      "end": 2675.417538000001,
      "zh": "所以这里有两个问题，对吧？为什么不能两者都做呢？还有就是根据我们的估算，到2028年你的容量会少三吉瓦半。当然，你可以把这部分专门给OpenAI做training和inference，但你也可以把这三吉瓦半用来运行Azure、Microsoft 365、GitHub、Copilot。其实不用非得给OpenAI。",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2675.517538000001,
      "end": 2787.657538000001,
      "zh": "\"或者我可能想在不同的地方建，比如阿联酋、印度、欧洲，对吧？就像我说的，现在我们有实际的容量限制，因为法规和数据主权的要求，我们得在全球各地建。首先，美国本土的容量很重要，我们会全面建设。但当我展望2030年时，我有一个全球视角，考虑微软的业务形态，包括自有和第三方的需求，前沿合作伙伴想要多少，以及我们为多个模型和自家研究计算需求要建的推理容量。这些都是我考虑的因素，而不是因为暂停而放弃建设。我们意识到，我们想要的建设方式有些不同，要根据工作负载类型、地理位置和时间来调整。我们会继续增加吉瓦容量，问题是以什么速度、在哪些地方，以及如何遵循摩尔定律。比如，我真想在2027年超建三吉瓦半吗？还是说在2027、2028年分散建设？我们从Nvidia学到的一点是，他们的进步速度很快，所以我不想被困在一个四五年的折旧周期。我想要的其实是像Jensen建议的那样，做到光速执行。这就是为什么在亚特兰大的数据中心能在90天内从获取到交付给真实工作负载，这就是他们的光速执行。我想在这方面做得更好，这样我就能在每一代架构上扩展，每五年就有更平衡的布局，不会一下子建太多，然后因为堆积在一个地方被卡住。比如在一个地方建很多可能适合training，但不一定适合inference，因为即使是异步的，欧洲也不会让我来回跑德州。这些都是我要考虑的事情。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2787.7575380000007,
      "end": 2799.4023510000006,
      "zh": "\"你怎么解释最近几周的行动呢？你们宣布和Iris Energy、Nebius、Lambda Labs合作，还有更多正在谈。你们去外面租Neo clouds的容量，而不是自己建。这是怎么回事呢？\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2799.5023510000005,
      "end": 2833.4503510000004,
      "zh": "我觉得这对我们来说挺好的，因为如果有需求，我们可以看到谁在建，我们就能服务到那里。其实，我们会去租赁，定制建造，甚至用GPU服务来解决我们没法提供的容量，而别人有的。而且，我很欢迎每个NEO cloud加入我们的市场。这样的话，他们把容量带到我们的市场，通过Azure来的客户就会用NEO cloud，这对他们是个好事。我们会用Azure的计算、存储、数据库等等。所以我并不觉得我们应该自己吞下这些。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2833.550351000001,
      "end": 2852.412101000001,
      "zh": "\"所以你提到要折旧这个五六年的资产，而这占了数据中心TCO的75%。Jensen在这上面有75%的利润。所以所有的超大规模公司都在尝试开发自己的加速器，想办法降低设备的高昂成本，提高利润。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 2852.5121010000007,
      "end": 2870.296101000001,
      "zh": "对啊，你看他们现在在哪儿，Google走在最前面，他们做这个最久了，他们要生产五到七百万自己的TPU芯片。再看Amazon，他们想做三到五百万。但微软自己订的芯片数量远远低于这个。你们的内部芯片项目也有一段时间了，这是什么情况呢？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2870.3961010000007,
      "end": 2949.9921010000007,
      "zh": "所以，有几件事要说。首先，任何新加速器最大的竞争对手其实就是Nvidia的上一代。对吧？我会看整个TCO（总拥有成本）。就算是我们自己的加速器，我的标准也是一样的。顺便说一下，我刚看了Maya 200的数据，表现不错。我们在计算方面的经验是，先用很多Intel，然后引入AMD，再引入Cobalt，这样逐步扩大。所以我们在核心计算方面，有很好的自建芯片和管理多样化设备的经验。因为就连Google和Amazon也在买Nvidia，这很合理，因为Nvidia一直在创新，而且它是通用的，所有模型都能用，客户需求也大。如果你自己做垂直整合，必须有自己的模型，要么用于training，要么用于inference。你得自己创造需求或者补贴需求，所以要确保规模合适。我们的做法是让自家的MAI模型和芯片紧密结合。我觉得这才是自建芯片的关键，因为你是根据自己的需求设计微架构，并跟上自己模型的节奏。好消息是，OpenAI有个项目，我们可以参与。所以认为微软不会有自己的东西，那是不可能的。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2950.0921010000006,
      "end": 2952.6463200000007,
      "zh": "\"你们对这个有多大权限呢？\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2952.7463200000007,
      "end": 2954.0234450000007,
      "zh": "完全有权限。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2954.1234450000006,
      "end": 2959.4529140000004,
      "zh": "你们只需要拿到所有相关的IP就行了，唯一不涉及的就是消费级硬件的IP。",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2959.552914000001,
      "end": 2961.642727000001,
      "zh": "\"就这样。哇，真厉害。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 2961.7427270000007,
      "end": 2963.9950710000007,
      "zh": "\"好吧，嗯，有意思。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 2964.0950710000006,
      "end": 3010.9670710000005,
      "zh": "对啊，顺便说一下，我们也给了他们一堆IP来启动他们。所以他们能有这么大的进展是有原因的。因为我们一起建了这些超级计算机，或者说我们为他们建的，他们从中受益，现在他们在系统层面创新，我们也能第一时间接触到这些。我们先用他们的成果，然后再扩展。所以说，微软想成为Nvidia的一个超强执行伙伴。说实话，那些设备本身就很重要，我不担心。Jensen做得很好，利润也不错，但总拥有成本还有很多方面，我希望在这方面也能做得很好。另外，我也想和OpenAI及MAI紧密合作。因为我们在系统设计上两边都有IP权限。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3011.067071000001,
      "end": 3034.395071000001,
      "zh": "说到权限，你知道，几天前你接受采访时说我们对你和OpenAI的新协议有权限。你们有权独占OpenAI的stateless API调用。我们有点困惑，到底有没有任何状态。我是说，你刚才提到这些复杂的工作负载需要内存、数据库和存储等等。那现在不算是stateless吗？如果ChatGPT在这样的情况下存储东西。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3034.4950710000007,
      "end": 3059.623071000001,
      "zh": "但这就是原因所在。我们做这个商业和战略决策，就是为了给OpenAI提供灵活性，方便他们获取计算资源。简单来说，OpenAI有两个业务：PaaS和SaaS。SaaS业务就是ChatGPT，PaaS业务就是他们的API。这个API是Azure独占的，而SaaS业务他们可以自己运营。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3059.723071000001,
      "end": 3063.600821000001,
      "zh": "\"他们可以在任何地方和任何想合作的人一起开发SaaS产品。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3063.700821000001,
      "end": 3074.022102000001,
      "zh": "\"所以如果他们想找个伙伴，而这个伙伴想用stateless API，那Azure就是可以提供stateless API的地方。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3074.1221020000007,
      "end": 3077.953415000001,
      "zh": "\"看起来他们可以一起开发产品，而且是有状态的。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3078.0534150000008,
      "end": 3093.413415000001,
      "zh": "“不，即使是那样，他们也得来Azure。就是说，不管是哪家合作伙伴。其实，这都是基于我们合作的价值观，同时也确保我们是OpenAI的好伙伴，给他们足够的灵活性。”",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3093.513415000001,
      "end": 3108.397415000001,
      "zh": "比如说，Salesforce想整合OpenAI，不是通过API。他们实际上是一起合作，一起训练一个model，然后一起部署在，比如说Amazon上。那这样可以吗？或者他们...",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3108.4974150000007,
      "end": 3117.1584780000007,
      "zh": "“这种定制协议必须用吗？他们得来Azure运行。除了个别像美国政府的例外，其他都得来Azure。”",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3117.2584780000007,
      "end": 3186.7024780000006,
      "zh": "所以就像Satya解释的，随着AI agents变得越来越强，你需要更多的观察能力来了解它们在做什么。你要能抓住它们出错的时候，还需要总结它们的工作，了解它们的整体表现。Code Rabbit就是做这个的。你只要提交一个普通的pull request，coderabbit就会自动审核，生成变更总结，让你明白PR作者的意图。它还会结合你整个代码库的上下文，逐行给出改进建议。不管你是在审查同事还是agent的PR，coderabbit都会提出意见，标出问题，让你的队友或agent去修正。我发现和agents一起写代码时，coderabbit能抓住很多模型默认会犯的错误。比如，模型经常用旧版库，Code Rabbit就能发现这种问题，找到新版本并建议改进。想了解更多可以去coderabbit AI官网看看。退一步说，我有个问题，就是当我们在工厂来回走的时候，你提到微软。你可以把它看成软件公司，但现在它真的变成一个工业公司了。这么多资本支出，这么多建设，两年内你的资本支出翻了三倍，再往后推，就像是个巨大的工业爆发。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3186.8024780000005,
      "end": 3203.3264780000004,
      "zh": "其他大厂都在借钱，对吧？Meta在路易斯安那借了200亿，他们搞了个企业贷款。看起来大家的自由现金流都快归零了，我敢肯定，Amy要是知道你也这么干，肯定会找你麻烦。但我觉得这里有个结构性的问题。",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3203.4264780000003,
      "end": 3270.4944780000005,
      "zh": "你说的变化，我觉得很大。我们现在既是资本密集型，又是知识密集型的公司。我们得用知识来提高资本回报率。你看硬件公司把摩尔定律宣传得那么好，我觉得很厉害。但如果你看我在财报里提到的一些数据，比如GPT家族的改进，软件在每美元每瓦的token吞吐量上，季度比季度、年比年都有巨大提升，可能是5倍、10倍，甚至40倍。这就是知识密集型带来的资本效率，我们得掌握这一点。有人问我，传统主机和超大规模主机的区别是什么？答案是软件。虽然资本密集，但只要你有系统知识和软件能力去优化工作负载和设备群，那就是我们说的可替代性，它里面有很多软件，不仅仅是设备群。能不能管理好调度算法？这就是我们要成为世界一流的地方。所以，我觉得我们还是会是个软件公司，但这确实是个不同的业务，我们要去管理。微软的现金流让我们能同时做好这两方面。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3270.5944780000004,
      "end": 3297.0184780000004,
      "zh": "嗯，看起来短期内事情会有点慢，有些曲折。但也许从长远来看，谈论AGI和ASI的人是对的，Sam可能会对。不过我有个更大的问题，就是对于一个超大规模公司来说，面对需要大量投资但五年就会折旧的东西，该怎么做才合理？如果你有20年、40年的时间表，而Sam预期三年能实现的东西，那在这样的世界里，你该怎么合理行动呢？",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3297.1184780000003,
      "end": 3333.4424780000004,
      "zh": "得给研究计算分配资源，就像做研发一样。对吧？其实这就是最合理的方式。我们应该把它看成研发开支，问问什么是研究计算，怎么扩展。对，假设在某个时间段内要扩大十倍吧。你选个时间，两年还是16个月之类的。这是一方面，算是基础配置，属于研发开支，剩下的就看需求了。最终你可以提前建设，但得有个靠谱的需求计划，不能偏得太离谱。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3333.5424780000003,
      "end": 3343.8173220000003,
      "zh": "\"你信吗？这些实验室现在预计在2027、2028年的收入会达到1000亿，而且他们预测收入会以三倍、两倍的速度持续增长。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3343.9173220000002,
      "end": 3402.7773220000004,
      "zh": "市场上一年。对，现在有各种激励措施，这也是应该的。你想想，一个独立实验室要筹钱，他们得拿出点数字来，好去筹钱，付计算费什么的。这也是好事，总得有人冒风险投进去，他们也有进展。不是说全是风险，像OpenAI或者Anthropic都做得不错。所以我对他们的成就挺满意的，我们和他们有大量业务往来，这很好。但总体来说，关键有两点。首先是得为研发分配资源，尤其是AI人才，现在AI人才很抢手，得在这上面花钱，也得在计算上花钱。所以研究人员和GPU的比例要高，这就是在这个世界做顶尖研发公司的要求。这个需要扩展，你得有能支持扩展的财务状况，早于常规智慧。这是一方面，另一方面就是要会预测，放眼全球去看。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3402.8773220000003,
      "end": 3475.2373220000004,
      "zh": "对，美国主导了很多技术栈，对吧。美国有Windows，通过微软部署，甚至在中国也是主流操作系统。当然还有开源的Linux，但你知道，Windows在中国的个人电脑上到处都是。你看Word，也是到处都有。这些技术无处不在。而微软和其他公司也在全球扩张，像是在欧洲、印度、东南亚、拉美和非洲建数据中心，增加容量。但现在看起来有点不一样，对吧？现在技术和计算的政治因素很重要。美国政府对当年的互联网泡沫不太在意，但现在对AI很关注，全球各国政府也是如此。问题是，我们处在一个至少是中美双极的世界，但欧洲、印度和其他国家都说，他们也要有自己的AI主权。微软怎么应对这种变化呢？以前90年代的时候，好像世界上只有美国一个重要国家，我们的公司可以到处卖产品，微软因此受益匪浅。现在却是个双极世界，微软不能理所当然地认为能赢得整个欧洲、印度或新加坡，因为各国都有自己的AI主权计划。你怎么看这个问题？你的想法是什么？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3475.3373220000003,
      "end": 3549.3533220000004,
      "zh": "我觉得这件事特别关键，美国科技行业和政府的首要任务，不仅是做创新工作，还要在全球建立对我们技术的信任。美国真是个了不起的地方，占世界人口4%，GDP的25%，市值的50%。这个比例很值得思考，因为这50%多亏了世界对美国的信任，无论是资本市场还是科技。如果这信任没了，对美国可不是什么好事。所以我觉得，不管是特朗普总统还是白宫，大家都明白这点。所以我支持美国政府和科技行业一起合作，比如说在全球各地冒风险投资。美国公司在全球的直接投资其实是最好的宣传，不只是吸引外资到美国，而是美国和美国公司在全球建立AI工厂。我们还需要围绕这些投资建立协议，尊重他们的主权，比如数据存储、隐私保障等。我们在欧洲的承诺也很重要，比如在法国和德国建立主权云服务，在Azure上提供主权服务，还和Nvidia合作做了很多创新的机密计算。我对建立这种对美国技术的信任非常有信心。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3549.4533220000003,
      "end": 3580.4853220000005,
      "zh": "那你怎么看这个问题？因为现在有网络效应，模型会不断学习，可能在超大规模计算这边也一样。你觉得各国会不会说，明显就是一个或几个模型最好，所以我们会用它们，但会有法律规定，比如权重得在我们国家存放。还是说，各国会推动必须在本国训练模型呢？就像半导体对经济很重要，大家都想有自己的半导体，但TSMC就是更好，所以你还是得去台湾买芯片。AI会不会也这样，还是说有别的可能？",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3580.5853220000004,
      "end": 3638.7973220000003,
      "zh": "关键是看各国怎么用AI来创造经济价值。对，这其实就是扩散理论，不是说要成为领先行业，而是利用领先技术来获得自己的比较优势。这会是核心驱动力。但是，他们也想要这种连续性，对吧？所以我觉得，这也是为什么总会有一些制衡，防止一个模型独占市场。开源就很重要，必然会有多个模型存在。这是确保连续性和避免集中风险的一种方式。就是说，我想要多个模型，还有开源的选择。这样一来，每个国家都会觉得不用担心只能用最好的模型，因为我可以把自己的数据和资源转移到别的模型上，不管是开源的还是其他国家的。集中风险和主权，也就是实际的自主权，是推动市场和市场结构的两个关键因素。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3638.8973220000003,
      "end": 3644.0521660000004,
      "zh": "\"这跟半导体不一样，对吧。你看，所有冰箱、汽车都有芯片。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3644.1521660000003,
      "end": 3650.6305410000004,
      "zh": "\"台湾制造一直存在到现在。到现在。大家现在都这样，对吧。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3650.7305410000004,
      "end": 3669.6665410000005,
      "zh": "你知道，如果台湾被切断了，美国这边就没有车和冰箱了。TSMC在亚利桑那的工厂也没法真正替代多少产量。所谓的主权有点像个骗局，对吧。我是说，有它是有意义的，也很重要，但不是真正的主权。我们是个全球经济体，不是吗？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3669.7665410000004,
      "end": 3748.7145410000003,
      "zh": "我觉得这有点像 Dylan 说的，我们到现在还没真正理解什么是韧性，也不知道该怎么做，对吧？所以任何国家，包括美国，现在都会想办法让一些关键供应链更自给自足。作为跨国公司，我必须把这当成首要任务。如果不这样做，那我就没考虑到这个国家长远的政策利益。当然，我不是说他们短期内不会做一些实际决策。全球化是没法倒退的，毕竟那些资本投资不能轻易转移。但同时，如果有人在华盛顿说我们不建半导体厂，他们就会被踢出美国，其他国家也一样。所以，我觉得我们公司必须尊重这些经验教训，不管是因为疫情让我们醒悟还是其他原因。总之，人们在说，全球化很好，让供应链全球化而且效率高。但韧性这个东西也很重要，我们需要韧性。所以这个特点会被逐步建立，你说的对，这不是一蹴而就的事情，不能一拍脑袋就把所有TSMC工厂搬到亚利桑那。但会有计划，我们应该尊重这些计划。我想迎接这个世界，顺应它未来的方向，而不是坚持我们的观点不尊重他们的看法。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3748.814541,
      "end": 3767.390541,
      "zh": "所以，我理解的是，每个国家都会希望有数据驻留、隐私保护之类的东西。而微软在这方面有特别的优势，因为你们跟这些国家有联系，有在这些国家建立数据中心的经验。所以，微软在这个对主权要求更高的世界里特别合适。",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3767.490541,
      "end": 3801.9425410000003,
      "zh": "是啊，我不是想说我们有什么特别的优势。我会说这就是我们业务的要求，几十年来我们一直在努力，并且会继续这样。所以我对Dylan之前问题的回答是，无论是在美国，或者当白宫和美国政府说希望我们多把晶圆产能留在美国，我们都很认真对待。或者是在数据中心和欧盟边界的问题上，我们也很认真。所以我觉得要尊重国家在主权上的合理关切，无论是软件还是硬件，我们都会去做。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3802.0425410000003,
      "end": 3822.1305410000004,
      "zh": "那我们进入一个像两极世界的状态，对吧？我们和中国之间，美国科技不只是和Amazon、Anthropic或者Google竞争。还有一大堆竞争对手。美国怎么重建信任？怎么让大家相信美国公司会是主要的供应商？你怎么看待和中国新兴公司竞争，比如字节跳动、阿里巴巴或者深海Moonshot？",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3822.2305410000004,
      "end": 3847.8985410000005,
      "zh": "所以，接着这个问题，有个担忧就是，我们现在聊AI变成了一个工业资本开支竞赛，你得在各种平台上快速建设。听到这，你就会想到中国，对吧？这算是他们的优势。特别是如果我们明年不打算搞ASI这样的突破，而是要花几十年去建设基础设施等等。你怎么看待中国的竞争？他们在这个领域是不是有优势？",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3847.9985410000004,
      "end": 3865.7825410000005,
      "zh": "对，这个问题问得好。其实你刚才就提到了为什么我觉得信任美国科技是最重要的。关键不在于技术能力，而是我能不能信任你这个公司，你这个国家和它的制度能不能成为长期供应商，这可能才是赢得世界的关键。",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3865.8825410000004,
      "end": 3868.7734470000005,
      "zh": "\"我觉得这是个不错的结束点。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3868.8734470000004,
      "end": 3869.6745410000003,
      "zh": "\"嗯。\"",
      "en": "",
      "speaker": 2
    },
    {
      "start": 3869.774541,
      "end": 3871.771479,
      "zh": "\"Satya，谢谢你来参与。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3871.8714790000004,
      "end": 3874.506948,
      "zh": "\"谢谢你们，非常感谢。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3874.6069480000006,
      "end": 3876.4413540000005,
      "zh": "\"嗯，谢谢。\"",
      "en": "",
      "speaker": 1
    },
    {
      "start": 3876.5413540000004,
      "end": 3877.899729,
      "zh": "\"很高兴来这儿。\"",
      "en": "",
      "speaker": 3
    },
    {
      "start": 3877.9997290000006,
      "end": 3881.1460420000008,
      "zh": "\"真是太高兴了。你们俩真是个好搭档。\"",
      "en": "",
      "speaker": 0
    },
    {
      "start": 3881.2460420000007,
      "end": 3896.9420420000006,
      "zh": "大家好，希望你们喜欢这一集。如果喜欢，最有帮助的就是分享给你觉得也会喜欢的人。如果能在你收听的平台上评分或留言，也很有帮助。如果有兴趣赞助播客，可以联系dwarkesh.com的广告。那我们下次见！",
      "en": "",
      "speaker": 1
    }
  ],
  "guests": [
    {
      "name": "Dwarkesh Patel",
      "role": "主持人",
      "bio": "",
      "twitter": ""
    },
    {
      "name": "Satya Nadella",
      "role": "嘉宾",
      "bio": "",
      "twitter": ""
    },
    {
      "name": "Dylan Patel",
      "role": "共同主持",
      "bio": "",
      "twitter": ""
    },
    {
      "name": "Scott Guthrie",
      "role": "特别嘉宾",
      "bio": "",
      "twitter": ""
    }
  ],
  "resources": [],
  "summary": {
    "zh": "在这期播客中，微软CEO Satya Nadella深入探讨了微软在通用人工智能（AGI）时代的战略布局。他强调了技术创新中的道德标准的重要性，并展示了微软如何通过大规模投资和与OpenAI的合作来推动AI技术的发展。Nadella还讨论了微软基础设施的未来视角，特别是数据中心的10倍提升和支持AI代理自主运作的能力。此外，他指出AI技术对生产力的革命性影响，强调企业需要在快速变化的技术环境中保持灵活性和创新能力。整场对话充满了深刻的行业洞察，揭示了未来科技发展的前沿动态。",
    "en": "In this podcast, Microsoft CEO Satya Nadella discusses Microsoft's strategy for the AGI era, emphasizing the importance of ethical standards in technological innovation. He outlines Microsoft's collaboration with OpenAI and significant infrastructure investments, including a tenfold increase in data center capabilities. Nadella highlights AI's transformative impact on productivity, stressing the need for businesses to remain adaptive and innovative. The conversation provides profound insights into the future dynamics of technology development."
  },
  "keyPoints": [
    {
      "title": "微软未来基础设施战略",
      "highlights": [
        "Satya Nadella强调未来50年的基础设施规划。",
        "微软不想依赖单一客户进行优化。",
        "基础设施将支持AI代理的自主工作。"
      ],
      "startAt": 62
    },
    {
      "title": "数据中心的10倍提升",
      "highlights": [
        "Fairwater 2是全球最强的数据中心。",
        "训练能力每18-24个月提升10倍。",
        "500万个网络连接用于大规模扩展。"
      ],
      "startAt": 120
    },
    {
      "title": "AI代理与生产力革命",
      "highlights": [
        "AI被视为认知放大器和守护天使。",
        "技术扩散速度快于以往任何革命。",
        "AI将显著提高生产力和经济增长。"
      ],
      "startAt": 313
    },
    {
      "title": "Azure开放性与合作策略",
      "highlights": [
        "微软在支持多个AI模型中占据优势。",
        "与OpenAI的合作提供创新灵活性。",
        "开源模型和数据流动性是成功关键。"
      ],
      "startAt": 1158
    }
  ]
}